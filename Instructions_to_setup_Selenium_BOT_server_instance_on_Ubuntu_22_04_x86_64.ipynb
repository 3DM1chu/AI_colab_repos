{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Login as root and setup needed packages**"
      ],
      "metadata": {
        "id": "HDuoIaxAQ0cl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVkgp710Qtep"
      },
      "outputs": [],
      "source": [
        "apt-get -y update & apt-get install -y python3-virtualenv libapache2-mod-wsgi-py3 apache2 python3.10-venv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make base directory for Flask website. Setup needed permissions to read, write and execute**"
      ],
      "metadata": {
        "id": "s1Rnoiw-Q7cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir -p /var/www/html/request_bot_instance\n",
        "sudo usermod -a -G www-data root\n",
        "sudo chgrp -R www-data /var/www\n",
        "sudo chmod -R g+w /var/www\n",
        "sudo find /var/www -type d -exec chmod 2775 {} \\;\n",
        "sudo chmod -R a+rwx /var/www"
      ],
      "metadata": {
        "id": "7EGmtNwmRC-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Go to this directory**\n",
        "\n"
      ],
      "metadata": {
        "id": "1YJAyvGvRLYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /var/www/html/request_bot_instance"
      ],
      "metadata": {
        "id": "vVB_kPa-RNmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup python environment and install required libraries with pip (python can be 3.10)**"
      ],
      "metadata": {
        "id": "nBFr-NLpRVY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIOHTTP-SOCKS5 WITH CHANGING EVERYTIME: https://github.com/HMaker/aiohttp-socks5"
      ],
      "metadata": {
        "id": "rS68oiZkpBdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python3 -m venv venv\n",
        "touch requirements.txt\n",
        "echo \"flask\n",
        "requests\n",
        "aiohttp\n",
        "asyncio\n",
        "asgiref\n",
        "git+https://github.com/HMaker/aiohttp-socks5.git@latest\n",
        "aioflask\n",
        "selenium\" > requirements.txt\n",
        "source venv/bin/activate\n",
        "pip3 install -r requirements.txt\n",
        "deactivate"
      ],
      "metadata": {
        "id": "kzbvQr9oRY0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--------- ONLY FOR YOUTUBE SCRAPER**"
      ],
      "metadata": {
        "id": "EvIzQNauRkS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup channels folders for logs and outputs (inside /var/www/html/request_bot_instance)**"
      ],
      "metadata": {
        "id": "hl1Nr8C4RgfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rm -r channels\n",
        "rm -r channels_failed\n",
        "mkdir channels\n",
        "sudo chmod -R a+rwx channels\n",
        "mkdir channels_failed\n",
        "sudo chmod -R a+rwx channels_failed"
      ],
      "metadata": {
        "id": "qdiqQOIXRsuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ONLY FOR YOUTUBE SCRAPER ------------**"
      ],
      "metadata": {
        "id": "zWIAKwG3R271"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--------- ONLY FOR SELENIUM SCRAPER**"
      ],
      "metadata": {
        "id": "SYVho0PXpuG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup Google Chrome and print its version**"
      ],
      "metadata": {
        "id": "kygCbQ4SR4R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "sudo dpkg -i google-chrome-stable_current_amd64.deb\n",
        "sudo apt-get install -f -y\n",
        "google-chrome --version"
      ],
      "metadata": {
        "id": "HEfrLUtpR7gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In /var/www/html/request_bot_instance\n",
        "Upload chromedriver to request_bot_instance folder\n",
        "Chrome driver version must be relevant to installed in last step**"
      ],
      "metadata": {
        "id": "2afMOTJFR9FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wget http://154.19.185.93/chromedriver\n",
        "sudo mv chromedriver /usr/local/bin\n",
        "sudo chown root:root /usr/local/bin/chromedriver\n",
        "sudo chmod +x /usr/local/bin/chromedriver"
      ],
      "metadata": {
        "id": "60A-3n6USKD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ONLY FOR SELENIUM SCRAPER ------------**"
      ],
      "metadata": {
        "id": "NR9QOaXCpx2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup wsgi file to operate Flask website (path in sys.path.insert must be relevant to main directory of flask website)**"
      ],
      "metadata": {
        "id": "7H2QyDq7Svx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "touch request_bot_instance.wsgi\n",
        "echo \"import sys\n",
        "sys.path.insert(0,'/var/www/html/request_bot_instance')\n",
        "from request_bot_instance import app as application\" > request_bot_instance.wsgi"
      ],
      "metadata": {
        "id": "bXCKq8-gSzzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **--------ONLY FOR ORACLE CLOUD**"
      ],
      "metadata": {
        "id": "KutxxrjJS6e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Allow port 80 on linux**"
      ],
      "metadata": {
        "id": "ZOTZ-vhQTEpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo apt install -y firewalld\n",
        "sudo firewall-cmd --zone=public --permanent --add-port=80/tcp\n",
        "sudo firewall-cmd --reload"
      ],
      "metadata": {
        "id": "G3AhCOdTTJSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ONLY FOR ORACLE CLOUD---------**"
      ],
      "metadata": {
        "id": "C4NOvg4YTNiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup apache website config in /etc/apache2/sites-available**"
      ],
      "metadata": {
        "id": "Zv-OOHLaTPJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /etc/apache2/sites-available\n",
        "nano request_bot.conf"
      ],
      "metadata": {
        "id": "_UeVLqBTqbFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMEMBER TO ADD ServerName and python-home!!!**"
      ],
      "metadata": {
        "id": "HFoeUtUYsSy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<VirtualHost *:80>\n",
        "\t# The ServerName directive sets the request scheme, hostname and port that\n",
        "\t# the server uses to identify itself. This is used when creating\n",
        "\t# redirection URLs. In the context of virtual hosts, the ServerName\n",
        "\t# specifies what hostname must appear in the request's Host: header to\n",
        "\t# match this virtual host. For the default virtual host (this file) this\n",
        "\t# value is not decisive as it is used as a last resort host regardless.\n",
        "\t# However, you must set it for any further virtual host explicitly.\n",
        "\t#ServerName www.example.com\n",
        "\n",
        "\tServerAdmin webmaster@localhost\n",
        "\tServerName *INSERT IP OF MACHINE OR SERVER HERE*\n",
        "\tDocumentRoot /var/www/html/request_bot_instance\n",
        "\n",
        "\tWSGIDaemonProcess request_bot_instance user=www-data group=www-data threads=5 python-home=*PATH TO PYTHON ENV*\n",
        "\n",
        "\tWSGIScriptAlias /request_bot_instance /var/www/html/request_bot_instance/request_bot_instance.wsgi\n",
        "\t<Directory /var/www/html/request_bot_instance>\n",
        "\t\tWSGIProcessGroup request_bot_instance\n",
        "\t\tWSGIApplicationGroup %{GLOBAL}\n",
        "\t\tOrder deny,allow\n",
        "\t\tAllow from all\n",
        "\t</Directory>\n",
        "\n",
        "\t# Available loglevels: trace8, ..., trace1, debug, info, notice, warn,\n",
        "\t# error, crit, alert, emerg.\n",
        "\t# It is also possible to configure the loglevel for particular\n",
        "\t# modules, e.g.\n",
        "\t#LogLevel info ssl:warn\n",
        "\n",
        "\tErrorLog ${APACHE_LOG_DIR}/error.log\n",
        "\tCustomLog ${APACHE_LOG_DIR}/access.log combined\n",
        "\n",
        "\t# For most configuration files from conf-available/, which are\n",
        "\t# enabled or disabled at a global level, it is possible to\n",
        "\t# include a line for only one particular virtual host. For example the\n",
        "\t# following line enables the CGI configuration for this host only\n",
        "\t# after it has been globally disabled with \"a2disconf\".\n",
        "\t#Include conf-available/serve-cgi-bin.conf\n",
        "</VirtualHost>\n",
        "\n",
        "# vim: syntax=apache ts=4 sw=4 sts=4 sr noet"
      ],
      "metadata": {
        "id": "io0NGccVTV6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add request_bot_instance.py to /var/www/html/request_bot_instance directory**"
      ],
      "metadata": {
        "id": "Z4-aO8hhrk8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nano request_bot_instance.py"
      ],
      "metadata": {
        "id": "NrALciDoruTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import random\n",
        "from aiohttp_socks5 import SOCKSConnector\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "class YoutubeScraper:\n",
        "    def __init__(self, YOUTUBE_CHANNEL_TAG, MAX_COUNT):\n",
        "        self.API_KEY = \"\"\n",
        "        self.NONCE_KEY = \"\"\n",
        "        self.BROWSE_ID = \"\"\n",
        "        self.MAX_COUNT = MAX_COUNT\n",
        "        self.YOUTUBE_START_TAG = \"hanmlbb7899\"         # some shitty video channel with less than 5 videos to just get keys\n",
        "        self.YOUTUBE_CHANNEL_TAG = YOUTUBE_CHANNEL_TAG # the channel we want to scrape\n",
        "        self.v = \"\"\n",
        "        self.bl = \"\"\n",
        "        self.x = \"\"\n",
        "        self.real_video_list = []\n",
        "        self.s = requests.Session()\n",
        "        self.CONTINUATION_TOKEN = \"\"\n",
        "        self.proxies = [ \"172.106.19.157:35461\", \"158.69.225.110:59166\", \n",
        "        \"138.197.203.84:59166\", \"142.44.241.192:59166\", \"135.148.46.53:3080\",\n",
        "        \"64.225.6.88:59166\", \"46.101.37.189:59166\", \"138.68.245.25:59166\", \"69.194.181.6:7497\",\n",
        "        \"174.138.33.62:59166\", \"162.216.18.189:59166\", \"167.99.168.124:59166\" ]\n",
        "        self.currentProxy = None\n",
        "    \n",
        "\n",
        "    def sendAndRetryIfNeeded(self, type, url, payload = None, headers = None):\n",
        "        maxTries = 10\n",
        "        while maxTries > 0:\n",
        "            try:\n",
        "                if type == \"GET\":\n",
        "                    if headers != None:\n",
        "                        return self.s.request(type, url, headers=headers, proxies=self.getProxy())\n",
        "                    else:\n",
        "                        return self.s.request(type, url, proxies=self.getProxy())\n",
        "                else:\n",
        "                    if payload != None:\n",
        "                        if headers != None:\n",
        "                            return self.s.request(type, url, headers=headers, proxies=self.getProxy(), data=payload)\n",
        "                        else:\n",
        "                            return self.s.request(type, url, proxies=self.getProxy(), data=payload)\n",
        "                    else:\n",
        "                        if headers != None:\n",
        "                            return self.s.request(type, url, headers=headers, proxies=self.getProxy())\n",
        "                        else:\n",
        "                            return self.s.request(type, url, proxies=self.getProxy())\n",
        "            except:\n",
        "                print(\"err with connecting...\")\n",
        "                time.sleep(0.5)\n",
        "                maxTries -= 1\n",
        "\n",
        "\n",
        "    def getProxy(self, randomize=False):\n",
        "        rand_proxy = random.randint(0, len(self.proxies)-1)\n",
        "        rand_proxy = self.proxies[rand_proxy]\n",
        "        if randomize:\n",
        "            self.currentProxy = {\n",
        "                'http': f'socks5://{rand_proxy}',\n",
        "                'https': f'socks5://{rand_proxy}'\n",
        "            }\n",
        "        else:\n",
        "            if self.currentProxy == None:\n",
        "                self.currentProxy = {\n",
        "                    'http': f'socks5://{rand_proxy}',\n",
        "                    'https': f'socks5://{rand_proxy}'\n",
        "                }\n",
        "        return self.currentProxy\n",
        "\n",
        "\n",
        "    def setupCookies(self):\n",
        "        url = f\"https://www.youtube.com/@{self.YOUTUBE_START_TAG}/\"\n",
        "        response = self.sendAndRetryIfNeeded(\"GET\", url)\n",
        "        #response = self.s.request(\"GET\", url, proxies=self.getProxy())\n",
        "        print(response)\n",
        "        print(self.getProxy())\n",
        "        lang = re.findall('(?<=lang=\")[\\w]+', response.text)[0].upper()\n",
        "        try:\n",
        "            self.v = re.findall('(?<=<input type=\"hidden\" name=\"v\" value=\")[\\w\\.+-:]+', response.text)[0]\n",
        "            self.bl = re.findall('(?<=<input type=\"hidden\" name=\"bl\" value=\")[\\w\\d\\.]+', response.text)[0]\n",
        "            self.x = re.findall('(?<=<input type=\"hidden\" name=\"x\" value=\")[\\d\\.]+', response.text)[0]\n",
        "            url = \"https://consent.youtube.com/save\"\n",
        "\n",
        "            payload = f\"gl={lang}&m=false&pc=yt&continue=https://www.youtube.com/@{self.YOUTUBE_START_TAG}?cbrd=1&x=8&v={self.v}&bl={self.bl}&hl=en&src=1&set_ytc=true&set_apyt=true&set_eom=false\"\n",
        "            headers = {\n",
        "                'Content-Type': 'application/x-www-form-urlencoded',\n",
        "                'Host': 'consent.youtube.com',\n",
        "            }\n",
        "            self.sendAndRetryIfNeeded(\"POST\", url, payload=payload, headers=headers) # get API KEYS and fill out the FORM\n",
        "            #self.s.request(\"POST\", url, headers=headers, data=payload, proxies=self.getProxy()) # get API KEYS and fill out the FORM\n",
        "        except:\n",
        "            print(\"ok maybe not needed...\")\n",
        "\n",
        "        #response = self.s.request(\"GET\", f\"https://www.youtube.com/@{self.YOUTUBE_START_TAG}?cbrd=1\", proxies=self.getProxy()) # get other keys\n",
        "        response = self.sendAndRetryIfNeeded(\"GET\", f\"https://www.youtube.com/@{self.YOUTUBE_START_TAG}?cbrd=1\") # get other keys\n",
        "\n",
        "        self.API_KEY = re.findall('(?<=INNERTUBE_API_KEY\":\")[\\w_]+', response.text)[0]\n",
        "        self.NONCE_KEY = re.findall('(?<=<script nonce=\")[\\w\\-\\.]+', response.text)[0]\n",
        "        self.BROWSE_ID = re.findall('(?<=\\\"browseId\\\":\\\")[\\w\\-]+', response.text)[0]\n",
        "        print(self.API_KEY, self.NONCE_KEY, self.BROWSE_ID)\n",
        "\n",
        "\n",
        "    def firstScrape(self):\n",
        "        #response = self.s.request(\"GET\", f\"https://www.youtube.com/@{self.YOUTUBE_CHANNEL_TAG}/videos\", proxies=self.getProxy())\n",
        "        response = self.sendAndRetryIfNeeded(\"GET\", f\"https://www.youtube.com/@{self.YOUTUBE_CHANNEL_TAG}/videos\")\n",
        "        yt_content_json = re.findall(f'(?<=var ytInitialData = ).+;<\\/script>', response.text)[0][:-10]\n",
        "        yt_content_json = json.loads(yt_content_json)\n",
        "\n",
        "        videos = yt_content_json[\"contents\"][\"twoColumnBrowseResultsRenderer\"][\"tabs\"][1][\"tabRenderer\"][\"content\"][\"richGridRenderer\"][\"contents\"]\n",
        "        #videos_count = yt_content_json[\"header\"][\"c4TabbedHeaderRenderer\"][\"videosCountText\"][\"runs\"][0]\n",
        "        #content = yt_content_json[\"contents\"][\"twoColumnBrowseResultsRenderer\"][\"tabs\"][0][\"tabRenderer\"][\"contents\"][\"sectionListRenderer\"]\n",
        "        #### SOME FUN PART HERE\n",
        "\n",
        "        for video_index in range(len(videos)-1):\n",
        "            video = videos[video_index]\n",
        "            self.real_video_list.append(video[\"richItemRenderer\"][\"content\"][\"videoRenderer\"])\n",
        "        try:\n",
        "            self.CONTINUATION_TOKEN = videos[len(videos)-1][\"continuationItemRenderer\"][\"continuationEndpoint\"][\"continuationCommand\"][\"token\"]\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def scrapeVideosDeeper(self):\n",
        "        self.s.headers[\"Content-Type\"] = \"application/json\"\n",
        "        payload = '{\"context\":{\"client\":{\"clientName\":\"WEB\",\"clientVersion\":\"2.20230206.06.00\",\"platform\":\"DESKTOP\"}}, \"browseId\":\"' + self.BROWSE_ID + '\", \"params\": \"' + self.NONCE_KEY + '\", \"continuation\": \"' + self.CONTINUATION_TOKEN + '\"}'\n",
        "        #response = self.s.request(\"POST\", \"https://www.youtube.com/youtubei/v1/browse?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8&prettyPrint=false\", data=payload, proxies=self.getProxy())\n",
        "        response = self.sendAndRetryIfNeeded(\"POST\", \"https://www.youtube.com/youtubei/v1/browse?key=AIzaSyAO_FJ2SlqU8Q4STEHLGCilw_Y9_11qcW8&prettyPrint=false\", payload=payload)\n",
        "\n",
        "        yt_content_json = json.loads(response.text)\n",
        "        videos = yt_content_json[\"onResponseReceivedActions\"][0][\"appendContinuationItemsAction\"][\"continuationItems\"]\n",
        "\n",
        "        for video_index in range(len(videos)-1):\n",
        "            video = videos[video_index]\n",
        "            self.real_video_list.append(video[\"richItemRenderer\"][\"content\"][\"videoRenderer\"])\n",
        "        if 'continuationItemRenderer' not in videos[len(videos)-1]:\n",
        "            print(f\"SCRAPED ALL {len(self.real_video_list)}^^\")\n",
        "            return\n",
        "        self.CONTINUATION_TOKEN = videos[len(videos)-1][\"continuationItemRenderer\"][\"continuationEndpoint\"][\"continuationCommand\"][\"token\"]\n",
        "        if len(self.real_video_list) <= self.MAX_COUNT:\n",
        "            time.sleep(0.1)\n",
        "            self.scrapeVideosDeeper()\n",
        "\n",
        "\n",
        "    async def scrapeAndSaveResults(self):\n",
        "        st = time.time()\n",
        "        self.setupCookies()\n",
        "        moreToScrape = self.firstScrape()\n",
        "        if moreToScrape:\n",
        "            self.scrapeVideosDeeper()\n",
        "\n",
        "        #f = open(f\"/var/www/html/selenium_bot/channels/@{self.YOUTUBE_CHANNEL_TAG}_raw.txt\", \"w\")\n",
        "        #f.write(json.dumps(self.real_video_list, indent=2, default=str))\n",
        "        #f.close()\n",
        "\n",
        "        video_list_to_save_to_file = []\n",
        "        for video in self.real_video_list:\n",
        "            video_id = video[\"videoId\"]\n",
        "            video_title = video[\"title\"][\"runs\"][0][\"text\"]\n",
        "            #videos_view_count = str(re.findall(\"((\\d{1,3})\\s?){1,}\", video[\"viewCountText\"][\"simpleText\"])[0]).replace(' ', '')\n",
        "            link_to_video = 'https://www.youtube.com/watch?v=' + video_id\n",
        "            video_obj = {\"link\": link_to_video, \"title\": video_title, \"channelTag\": self.YOUTUBE_CHANNEL_TAG}\n",
        "            video_list_to_save_to_file.append(video_obj)        \n",
        "        videos_arr = await self.check_async_video(video_list_to_save_to_file)\n",
        "\n",
        "        f = open(f\"/var/www/html/selenium_bot/channels/@{self.YOUTUBE_CHANNEL_TAG}.txt\", \"w\")\n",
        "        f.write(json.dumps(videos_arr, indent=2, default=str))\n",
        "        f.close()\n",
        "\n",
        "        et = time.time()\n",
        "        elapsed_time = et - st\n",
        "        print('Execution time:', elapsed_time, f'seconds, scraped {len(self.real_video_list)} videos')\n",
        "\n",
        "\n",
        "    async def fetch_video_info(self, video, session):\n",
        "        resp = \"\"\n",
        "        link_to_video = video[\"link\"]\n",
        "        title = video[\"title\"]\n",
        "        video_obj = {}\n",
        "        try:\n",
        "            prox = self.getProxy(randomize=True)[\"https\"]\n",
        "            async with session.get(url=link_to_video, proxy=prox) as response:\n",
        "                resp = await response.text()\n",
        "                print(\"Successfully got url {} with resp of length {}.\".format(link_to_video, len(resp)))\n",
        "                video_html = str(resp.encode('utf-8'))\n",
        "                resp = video_html\n",
        "                video_tags = re.findall(r'(?<=<meta name=\"keywords\" content=\")[\\w ,#\\.\\,]+', video_html)[0]\n",
        "                thumbnail = re.findall(r'(?<=<link itemprop=\"thumbnailUrl\" href=\")[\\/\\w\\:\\.]+', video_html)[0]\n",
        "                video_genre = re.findall(r'(?<=<meta itemprop=\"genre\" content=\")[\\/\\w\\:\\.]+', video_html)[0]\n",
        "                video_publish_date = re.findall(r'(?<=<meta itemprop=\"datePublished\" content=\")[\\/\\w\\:\\.-]+', video_html)[0]\n",
        "                video_desc = re.findall(r'(?<=\"shortDescription\":\").*?\"', video_html)[0]\n",
        "                video_length = re.findall(r'(?<=,\"lengthSeconds\":\")\\d+', video_html)[0]\n",
        "                video_views = re.findall(r'(?<=<meta itemprop=\"interactionCount\" content=\")\\d+', video_html)[0]\n",
        "                video_obj = {\n",
        "                    \"link\": link_to_video.split(\"https://www.youtube.com/\")[1],\n",
        "                    \"title\": title,\n",
        "                    \"tags\": str(video_tags),\n",
        "                    \"scraped_at\": time.time(),\n",
        "                    \"genre\": video_genre,\n",
        "                    \"views\": video_views,\n",
        "                    \"desc\": video_desc,\n",
        "                    \"lengthSeconds\": video_length,\n",
        "                    \"uploadDate\": str(video_publish_date),\n",
        "                    \"thumbnail_url\": str(thumbnail)\n",
        "                }\n",
        "            return video_obj\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(\"Unable to get url {} due to {}. RETRYING...\".format(link_to_video, e.__class__))\n",
        "            with open(\"/var/www/html/selenium_bot/channels_failed/\" + video[\"channelTag\"] + \".txt\", \"a\") as f:\n",
        "                f.write('Unable to get url {} due to {}.\\n'.format(link_to_video, e.__class__))\n",
        "                f.write(resp)\n",
        "                f.write('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
        "            while True:\n",
        "                try:\n",
        "                    video_obj = await self.fetch_video_info(video, session)\n",
        "                    return video_obj\n",
        "                except:\n",
        "                    print(\"Unable to get url {} RETRYING...\".format(link_to_video))\n",
        "\n",
        "\n",
        "    async def check_async_video(self, videos):\n",
        "        videos_arr = []\n",
        "        \n",
        "        #connector = ProxyConnector(host=prox[0], port=int(prox[1]), proxy_type=ProxyType.SOCKS5)\n",
        "        async with aiohttp.ClientSession(connector=SOCKSConnector()) as session:\n",
        "            videos_arr = await asyncio.gather(*[self.fetch_video_info(video, session) for video in videos])\n",
        "        print(\"Finalized all. Return is a list of len {} outputs.\".format(len(videos_arr)))\n",
        "        return videos_arr\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"I'm alive\"\n",
        "\n",
        "\n",
        "@app.route('/add-yt-record', methods=['POST'])\n",
        "def append_youtube_channel():\n",
        "    if request.method == 'POST':\n",
        "        content = request.json\n",
        "        f = open(\"/var/www/html/selenium_bot/channels/\" + content[\"channelTag\"] + \".txt\", \"w\")\n",
        "        f.write(json.dumps(content, indent=2))\n",
        "        f.close()\n",
        "    return json.dumps({\"resp\": \"OK\"})\n",
        "\n",
        "\n",
        "@app.route('/fetch-yt-channel', methods=['POST'])\n",
        "async def receive_youtube_channel_scrape_request():\n",
        "    if request.method == 'POST':\n",
        "        content = request.json\n",
        "        channel_tag = content[\"channel_tag\"]\n",
        "        max_vids = content[\"maxCount\"]\n",
        "        print(content)\n",
        "        await YoutubeScraper(channel_tag, max_vids).scrapeAndSaveResults()\n",
        "    return json.dumps({\"resp\": \"OK\"})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":  # Makes sure this is the main process\n",
        "    app.run()\n"
      ],
      "metadata": {
        "id": "wPeR0dOkrxhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deploy config and restart apache**"
      ],
      "metadata": {
        "id": "J1MvDoaSTwzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sudo a2ensite request_bot_instance.conf\n",
        "sudo a2enmod wsgi\n",
        "sudo service apache2 restart\n",
        "systemctl status apache2.service"
      ],
      "metadata": {
        "id": "JLq5Df2JTzsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To get last 50 logs from apache put this command below (can be without clear)**"
      ],
      "metadata": {
        "id": "7y34R5j0T1tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clear & sudo tail -50 /var/log/apache2/error.log"
      ],
      "metadata": {
        "id": "C43Ur-ofT4Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To remove chrome logs**"
      ],
      "metadata": {
        "id": "50wp-c-ERkJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rm -r /tmp/.com.google.Chrome.*"
      ],
      "metadata": {
        "id": "CveUPcKYRg1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}