{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport numpy as np\nimport transformers\nfrom transformers import BertTokenizer\nfrom torch import nn\nfrom transformers import BertModel\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport re\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-13T17:37:20.686363Z","iopub.execute_input":"2023-03-13T17:37:20.686642Z","iopub.status.idle":"2023-03-13T17:37:20.698351Z","shell.execute_reply.started":"2023-03-13T17:37:20.686613Z","shell.execute_reply":"2023-03-13T17:37:20.696843Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/yt-comments-bias-tips-normal/learn_yt_comments.csv\n/kaggle/input/dataset-for-testing-yt-comms-bias/test_yt_comments.csv\n/kaggle/input/fine-tune-chat-gpt/learn_yt_comments fine-tune.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# THIS SCRIPT ANALYZES YOUTUBE COMMENTS\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast=False)\nlabels = {'extra': 0,\n          'normal': 1,\n          'question': 2,\n          'timestamps': 3,\n          'issue': 4\n          }\nlabels2 = ['extra', 'normal', 'question', 'timestamps', 'issue']\n\ndf = pd.read_csv(\"../input/fine-tune-chat-gpt/learn_yt_comments fine-tune.csv\")\ndf_test = pd.read_csv(\"../input/dataset-for-testing-yt-comms-bias/test_yt_comments.csv\")\n\ndf.head()\n\ni = 0\nfor text in df['text']:\n    text = re.sub(\"[.,!?-]\", '', text.lower())\n    text = re.sub(\"\\s{2,}\", ' ', text.lower())\n    df['text'][i] = text\n    i+=1\n\nnp.random.seed(75)\ndf_train, df_val = np.split(df.sample(frac=1, random_state=12), [int(.95*len(df))])\n\nprint(df_train.head())\nprint(df_train.at[2, 'category'])\n\nprint(len(df_train), len(df_val), len(df_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:16.825613Z","iopub.execute_input":"2023-03-13T22:47:16.826789Z","iopub.status.idle":"2023-03-13T22:47:21.427935Z","shell.execute_reply.started":"2023-03-13T22:47:16.826738Z","shell.execute_reply":"2023-03-13T22:47:21.426794Z"},"trusted":true},"execution_count":174,"outputs":[{"name":"stdout","text":"       category                                               text\n19440    normal  you should check out the book disclosure proto...\n830       extra  i don't know if you did it intentionally or no...\n16233  question  i still have problems with characters that hav...\n4509     normal  even these have the typical 'midjourney' style...\n570       extra  filtering the labels based on the confidence l...\nextra\n18701 985 1038\n","output_type":"stream"}]},{"cell_type":"code","source":"def text_preprocessing(text):\n    \"\"\"\n    - Remove entity mentions (eg. '@united')\n    - Correct errors (eg. '&amp;' to '&')\n    @param    text (str): a string to be processed.\n    @return   text (Str): the processed string.\n    \"\"\"\n    \n    text = text.lower()\n    text = re.sub(r\"what's\", \" what is \", text)\n    text = re.sub(r\"\\'s\", \" is \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \" can not \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \" i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    text = re.sub(r\"\\'\\n\", \" \", text)\n    text = re.sub(r\"\\'\\xa0\", \" \", text)\n    \n    # Remove '@name'\n    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n    # Replace '&amp;' with '&'\n    text = re.sub(r'&amp;', '&', text)\n    \n    text = re.sub(r'https?:\\/\\/[\\w\\-!@#$%\\/\\^&*\\.\\(\\)\\d=]+', ' extra_link ', text)  # replace links with extra_link\n    text = re.sub(r'\\w+(-{1,2}[\\w]{2,}){1,}', ' extra_command ', text) # dont use apt-get command` => 'apt-get' goes => 'extra_command'\n    text = re.sub(r'(-{1,2}[\\w]{2,}){1,}', ' extra_argument ', text) # extra, the `--no-half` => '--no-half' goes => 'extra_argument'\n    text = re.sub(r'\\d{1,2}:(\\d\\d?:?){1,}', ' extra_timestamp ', text) # 10:01 to 10:40:3 => extra_timestamp to extra_timestamp\n    text = re.sub(r'\\d+',' extra_number ', text) # replace numbers with extra_number\n    text = re.sub(r'=', ' equals ', text) # replace = with equals\n    \n    text = re.sub(r'[^\\w\\s]',' ', text)\n    #text = re.sub(r'\\s+[a-zA-Z]\\s+',' ', text)\n    text = re.sub(r' the ',' ', text)\n    text = re.sub(r' and ',' ', text)\n    text = re.sub(r' or ',' ', text)\n    text = re.sub(r\"-\", \" - \", text)\n\n    # Remove trailing whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:25.059976Z","iopub.execute_input":"2023-03-13T22:47:25.061155Z","iopub.status.idle":"2023-03-13T22:47:25.073761Z","shell.execute_reply.started":"2023-03-13T22:47:25.061079Z","shell.execute_reply":"2023-03-13T22:47:25.072647Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"print(text_preprocessing(\"extra, knowing that alfa+beta=127 for the reasons mentioned i have considered the quadrilateral efcd from which x + 53 + 180 - alpha + 180 - beta = 360 that easily leads to x=74\"))\nprint(text_preprocessing(\"dude it's c1 = a1b1 + a2b3 it's written literally under the picture...\"))\nprint(text_preprocessing(\"extra,1:04:34 for training very deep transformers see https://arxiv.org/pdf/2003.04887.pdf\"))\nprint(text_preprocessing(\"extra,2:57 you mean \\alpha_n = \\frac{1}{\\lambda} (y_n - w^t\\phi(x_n)) without the \\sum operator. had me confused for a while.\"))\nprint(text_preprocessing(\"extra,@ 28:32 protoattend ( https://arxiv.org/abs/1902.06292) is what you're looking for\"))\nprint(text_preprocessing(\"extra,commands: open powershell as admin set-executionpolicy remotesigned install-module pswindowsupdate import-module pswindowsupdate get-windowsupdate install-windowsupdate\"))\nprint(text_preprocessing(\"extra,adding --seed --stylize @ 16:17  just wonder if using a --seed referenced to a previous render of boy-girl-rabbit-pool along with the two image references could help maintain character consistencies: hair clothing (style & color) as well as introducing a lower level of --stylize 50 to reduce the midjourney induced variability within the new renderings any ideas wish i had the time to play with midjourney. you do good work! thank you. ( --stylize per midjourney: low stylization values produce images that closely match the prompt but are less artistic. high stylization values create images that are very artistic but less connected to the prompt.)\"))\nprint(df_train['text'][15:35])\nfor i in df_train.index:\n    df_train['text'][i]=text_preprocessing(df_train['text'][i])\nprint(df_train['text'][15:35])","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:26.913390Z","iopub.execute_input":"2023-03-13T22:47:26.914002Z","iopub.status.idle":"2023-03-13T22:47:33.739057Z","shell.execute_reply.started":"2023-03-13T22:47:26.913964Z","shell.execute_reply":"2023-03-13T22:47:33.737650Z"},"trusted":true},"execution_count":176,"outputs":[{"name":"stdout","text":"extra knowing that alfa beta equals extra_number for reasons mentioned i have considered quadrilateral efcd from which x extra_number extra_number alpha extra_number beta equals extra_number that easily leads to x equals extra_number\ndude it is c extra_number equals a extra_number b extra_number a extra_number b extra_number it is written literally under picture\nextra extra_timestamp for training very deep transformers see extra_link\nextra extra_timestamp you mean lpha_n equals rac extra_number lambda y_n w t phi x_n without sum operator had me confused for a while\nextra extra_timestamp protoattend extra_link is what you are looking for\nextra commands open powershell as admin extra_command remotesigned extra_command pswindowsupdate extra_command pswindowsupdate extra_command extra_command\nextra adding extra_argument extra_argument extra_timestamp just wonder if using a extra_argument referenced to a previous render of extra_command along with two image references could help maintain character consistencies hair clothing style color as well as introducing a lower level of extra_argument extra_number to reduce midjourney induced variability within new renderings any ideas wish i had time to play with midjourney you do good work thank you extra_argument per midjourney low stylization values produce images that closely match prompt but are less artistic high stylization values create images that are very artistic but less connected to prompt\n17404    phenomenal would you be able to step through t...\n5595     i actually started dancing really hard when mu...\n18561    what if you can have a constraint for the prun...\n8796     my company recently adopted dnac just want to ...\n6845     i think it is highly useful to train yourself ...\n15461    hi rodent amazing as always i have problem i i...\n6299     i just don't understand why you are not crawli...\n9470     postdoc salary in many places status of postdo...\n8747     moore's law we will have more n more computati...\n8027     it should be illegal to have laws or culture a...\n4549     exactly what i told my team curated informatio...\n14832    great thanks for sharing rob for similarity de...\n4567     excellent video i'm trying that right now :) t...\n64       1 if the person always goes all in the probabi...\n7132     i was having a lot of issues with wsl detectin...\n1452     not very convincing so far distribution of err...\n17593    so avatar isn't a real time thing right you re...\n17360    one question how do we apply/implement adaptiv...\n19113    @nvidia unfortunately you are asking a lot of ...\n7075     i ve mentally checked out of my phd years ago ...\nName: text, dtype: object\n17404    phenomenal would you be able to step through c...\n5595     i actually started dancing really hard when mu...\n18561    what if you can have a constraint for pruning ...\n8796     my company recently adopted dnac just want to ...\n6845     i think it is highly useful to train yourself ...\n15461    hi rodent amazing as always i have problem i i...\n6299     i just do not understand why you are not crawl...\n9470     postdoc salary in many places status of postdo...\n8747     moore is law we will have more n more computat...\n8027     it should be illegal to have laws culture agai...\n4549     exactly what i told my team curated informatio...\n14832    great thanks for sharing rob for similarity de...\n4567     excellent video i am trying that right now tha...\n64       extra_number if person always goes all in prob...\n7132     i was having a lot of issues with wsl detectin...\n1452     not very convincing so far distribution of err...\n17593    so avatar is not a real time thing right you r...\n17360    one question how do we apply implement adaptiv...\n19113    unfortunately you are asking a lot of my perso...\n7075     i ve mentally checked out of my phd years ago ...\nName: text, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.labels = [labels[label] for label in df['category']]\n        self.texts = [tokenizer(text,\n                               padding='max_length', max_length = 128, truncation=True,\n                                return_tensors=\"pt\") for text in df['text']]\n\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n\n    def __getitem__(self, idx):\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n        return batch_texts, batch_y","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:38.801038Z","iopub.execute_input":"2023-03-13T22:47:38.801797Z","iopub.status.idle":"2023-03-13T22:47:38.810346Z","shell.execute_reply.started":"2023-03-13T22:47:38.801755Z","shell.execute_reply":"2023-03-13T22:47:38.809013Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n        self.texts = [tokenizer(text,\n                               padding='max_length', max_length = 128, truncation=True,\n                                return_tensors=\"pt\") for text in df['text']]\n\n    def __len__(self):\n        return len(self.texts)\n\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n\n    def __getitem__(self, idx):\n        batch_texts = self.get_batch_texts(idx)\n\n        return batch_texts","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:40.454913Z","iopub.execute_input":"2023-03-13T22:47:40.455843Z","iopub.status.idle":"2023-03-13T22:47:40.463871Z","shell.execute_reply.started":"2023-03-13T22:47:40.455779Z","shell.execute_reply":"2023-03-13T22:47:40.462685Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n    \n    def __init__(self):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.linear = nn.Linear(768, 5)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask, return_dict=False)\n        linear_output = self.linear(pooled_output)\n        relu = self.relu(linear_output)\n        return relu","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:41.873384Z","iopub.execute_input":"2023-03-13T22:47:41.873753Z","iopub.status.idle":"2023-03-13T22:47:41.881333Z","shell.execute_reply.started":"2023-03-13T22:47:41.873720Z","shell.execute_reply":"2023-03-13T22:47:41.879944Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"def train(model, train_data, val_data, learning_rate, epochs):\n    train, val = Dataset(train_data), Dataset(val_data)\n\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    criterion = nn.CrossEntropyLoss()\n    \n    if use_cuda:\n        model = model.cuda()\n        \n    for epoch_num in range(epochs):\n\n        total_acc_train = 0\n        total_loss_train = 0\n        \n        optimizer = Adam(model.parameters(), lr=learning_rate)\n\n        for train_input, train_label in tqdm(train_dataloader):\n            train_label = train_label.to(device)\n            mask = train_input['attention_mask'].to(device)\n            input_id = train_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n\n            batch_loss = criterion(output, train_label.long())\n            total_loss_train += batch_loss.item()\n\n            acc = (output.argmax(dim=1) == train_label).sum().item()\n            total_acc_train += acc\n\n            model.zero_grad()\n            batch_loss.backward()\n            optimizer.step()\n\n        total_acc_val = 0\n        total_loss_val = 0\n        \n\n        with torch.no_grad():\n            for val_input, val_label in val_dataloader:\n                val_label = val_label.to(device)\n                mask = val_input['attention_mask'].to(device)\n                input_id = val_input['input_ids'].squeeze(1).to(device)\n\n                output = model(input_id, mask)\n\n                batch_loss = criterion(output, val_label.long())\n                total_loss_val += batch_loss.item()\n\n                acc = (output.argmax(dim=1) == val_label).sum().item()\n                total_acc_val += acc\n\n        print(\n            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n        torch.save(model.state_dict(), \"../working/model_yt.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:43.449225Z","iopub.execute_input":"2023-03-13T22:47:43.449597Z","iopub.status.idle":"2023-03-13T22:47:43.465310Z","shell.execute_reply.started":"2023-03-13T22:47:43.449567Z","shell.execute_reply":"2023-03-13T22:47:43.464021Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 1\nLR = 3e-5\ngc.collect()\ntorch.cuda.empty_cache()\nmodel = BertClassifier()\nmodel.load_state_dict(torch.load(\"../working/model_yt.pt\"))\n\ntrain(model, df_train, df_val, LR, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:47:50.332252Z","iopub.execute_input":"2023-03-13T22:47:50.332650Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n100%|██████████| 585/585 [03:31<00:00,  2.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.002                 | Train Accuracy:  0.985                 | Val Loss:  0.005                 | Val Accuracy:  0.960\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▊       | 168/585 [01:00<02:30,  2.78it/s]","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, test_data):\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0\n    with torch.no_grad():\n        i = 0\n        for test_input, test_label in test_dataloader:\n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n            print(nn.Softmax(output))\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            if labels2[output.argmax(dim=1).item()] != labels2[test_label.item()]:\n                print(labels2[output.argmax(dim=1).item()] + ',' + test_data.at[i, 'text'])\n            else:\n                print(test_data.at[i, 'category'] + ',' + test_data.at[i, 'text'])\n                #print(tokenizer.decode(test_dataloader.dataset.texts[i].input_ids[0])[:200], \"| IS | \", labels2[output.argmax(dim=1).item()], \" : \", labels2[test_label.item()])\n            total_acc_test += acc\n            i += 1\n\n    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:13:28.189312Z","iopub.execute_input":"2023-03-13T22:13:28.189735Z","iopub.status.idle":"2023-03-13T22:13:28.202730Z","shell.execute_reply.started":"2023-03-13T22:13:28.189698Z","shell.execute_reply":"2023-03-13T22:13:28.201634Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"def evaluateAndPrintForModel(model, test_data):\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    total_acc_test = 0\n    with torch.no_grad():\n        i = 0\n        for test_input, test_label in test_dataloader:\n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            #print(output[0])\n            #print(output[0][0].item())\n            #print(output[0][1].item())\n            #print(output[0][2].item())\n            #print(output[0][3].item())\n            #print(output[0][4].item())\n            #return\n            if labels2[output.argmax(dim=1).item()] != labels2[test_label.item()]:\n                print(labels2[output.argmax(dim=1).item()] + ',' + test_data.at[i, 'text'])\n            else:\n                print(test_data.at[i, 'category'] + ',' + test_data.at[i, 'text'])\n                #print(tokenizer.decode(test_dataloader.dataset.texts[i].input_ids[0])[:200], \"| IS | \", labels2[output.argmax(dim=1).item()], \" : \", labels2[test_label.item()])\n            total_acc_test += acc\n            i += 1\n\n    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:13:31.677852Z","iopub.execute_input":"2023-03-13T22:13:31.678239Z","iopub.status.idle":"2023-03-13T22:13:31.689821Z","shell.execute_reply.started":"2023-03-13T22:13:31.678207Z","shell.execute_reply":"2023-03-13T22:13:31.687413Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"def evaluateWithoutAccuracy(model, test_data):\n    test = TestDataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n    \n    resp = []\n    output = None\n    with torch.no_grad():\n        i = 0\n        for test_input in test_dataloader:\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n            output = torch.round(nn.Softmax(dim=1)(output), decimals = 3)\n            \n            #print(tokenizer.decode(test_dataloader.dataset.texts[i].input_ids[0])[:100], \" |||| \", labels2[output.argmax(dim=1).item()])\n            resp.append(tokenizer.decode(test_dataloader.dataset.texts[i].input_ids[0])[:200] + \" |||| \" + labels2[output.argmax(dim=1).item()])\n            i += 1\n    return [resp, output]","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:21:22.157689Z","iopub.execute_input":"2023-03-13T22:21:22.158060Z","iopub.status.idle":"2023-03-13T22:21:22.168474Z","shell.execute_reply.started":"2023-03-13T22:21:22.158027Z","shell.execute_reply":"2023-03-13T22:21:22.167313Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"evaluate(model,df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateAndPrintForModel(model, df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_to_add = []","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:15:13.366989Z","iopub.execute_input":"2023-03-13T22:15:13.367980Z","iopub.status.idle":"2023-03-13T22:15:13.373434Z","shell.execute_reply.started":"2023-03-13T22:15:13.367940Z","shell.execute_reply":"2023-03-13T22:15:13.372272Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"while 1:\n    query = input(\"Text to check:\")\n    query = query.replace(',', '').replace('\\\"', '').replace('\\.', ' ').replace('\\n', '').replace('\\r', '').replace('\\t','').replace('  ', '').strip().lower()\n    if query == 'stop':\n        break\n    if len(query) < 25:\n        continue\n    df_test_input = pd.DataFrame({\"text\": [query]})\n    evaluated_resp, tensor = evaluateWithoutAccuracy(model, df_test_input)\n    evaluated_resp = evaluated_resp[0]\n    output = evaluated_resp.split(\"|||| \")[1]\n    print(output)\n    metric = torch.topk(tensor, 2)\n    firstOutput = metric[0][0][0].item()\n    secondOutput = metric[0][0][1].item()\n    overallScore = firstOutput + secondOutput\n    howSure = (firstOutput / overallScore) * 100\n    print(howSure)\n    if howSure < 70:\n        print(\"Sadly not sure...\")\n        continue\n    text = input(\"Correct? [y/n]\")\n    if text == 'y':\n        text_to_add.append(f'{output},{query}')\n        print(\"Added, curr len: \" + str(len(text_to_add)))\n    else:\n        new_output = input(\"New category:\")\n        text_to_add.append(f'{new_output},{query}')\n        print(\"Added, curr len: \" + str(len(text_to_add)))\n        \n        \n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T22:30:15.105695Z","iopub.execute_input":"2023-03-13T22:30:15.108740Z","iopub.status.idle":"2023-03-13T22:46:43.127253Z","shell.execute_reply.started":"2023-03-13T22:30:15.108687Z","shell.execute_reply":"2023-03-13T22:46:43.124189Z"},"trusted":true},"execution_count":173,"outputs":[{"output_type":"stream","name":"stdin","text":"Text to check: your information about midjourney is clear and concise. many thanks. recently i created amazing images with bluewillow and it's super cool. it's completely free. what do you think about bw\n"},{"name":"stdout","text":"question\n99.79979978610527\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3776089110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sadly not sure...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Correct? [y/n]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtext_to_add\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{output},{query}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m         )\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}]},{"cell_type":"code","source":"for text in text_to_add:\n    query = text.replace('\\\"', '').replace('\\.', ' ').replace('\\n', '').replace('\\r', '').replace('\\t','').replace('  ', '').strip().lower()\n    print(query)","metadata":{"execution":{"iopub.status.busy":"2023-03-06T17:34:53.819720Z","iopub.execute_input":"2023-03-06T17:34:53.820388Z","iopub.status.idle":"2023-03-06T17:34:53.827816Z","shell.execute_reply.started":"2023-03-06T17:34:53.820351Z","shell.execute_reply":"2023-03-06T17:34:53.826731Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"normal,i want to try runway. i think it is an awesome software!\nquestion,does gpt 3 require a paid account? i tried to access it to no avail.\nquestion,very nice content. thanks for the research. i would like to know if there is an ai application for predicting the next set of a group of numbers?or one that helps to quickly develop mobile apps?\nquestion,this is so interesting!! it’s insane to see how technology develops. but would these ais like bhuman be able to read non-english names correctly or is that something to wait for?\nquestion,quick question if anyone knows: how is the pricing determined on these illustrations? do you set your own or does adobe and the other ones which accept ai generated images decide?\nextra,you also need a midjourney commercial license to sell the images generated there. otherwise they fall under the creative commons noncommercial 4.0 attribution international license (the “asset license”).\nquestion,this is awesome thank you matt. question - do you know how i could change my png file to jpg with a maximum size of 45mb and minimum resolution of 4mp. i appears when i try to load my art to wirestock it tells me that they do not meet the requirements. however i am using the same files that i loaded into adobe stock successfully.\nextra,i tried a ton of the image upscalers and settled on the exact same ones as you upscale media for free and gigapixel for paid. for the free one i got best results by doing 2x with enhance and then 2x without.great tutorial ty\nquestion,this is so cool. thank you matt! hey two questions. one if i upload images to one or more of these sites can i still use them too? two you said adobe stock was the only site to let you use ai generative art but then you used that wire-thing site to upload to shutterstock etc. do all those sites know it's ai art and are okay with it? (bonus question: did you have to create an account on all those other sites first?) thanks again!\nnormal,thanks for the detailed walkthrough mate! i love creating ai art so may as well try make some dollars with it. i'm sure overtime it will add up\nquestion,as the legal things are so confusing to a layman like me i have understood that you can only sell images created by the lisenced/paid version of midjourney. how about bluewillow which creates quite different style pictures? any knowledge of that?\nquestion,love your channel btw!can you use a prompt that would reference the style of a deceased artist.such as create a brain in the style of picasso with books and . . . would that be a usage infringement?\nquestion,how much does adobe charge for stock photos and what percent do you get from the sell? do you have to remove any watermarks?\nquestion,thanks for all your brilliant content and future tools! do you use a free photo editor (shown in this video)? if so which one?\nquestion,do i have to pay a monthly fee for adobe stock if i only want to upload and sell my own images?\nquestion,this is pretty cool!!does anyone know if there is a way to add your signature to the lower left/right side of these images.not large of course but just so it's there.thanks in advance either way if anyone knows!\nquestion,hey matt!you're videos are great and i really appreciate them all.can you tell me out of all these ways of making money with ai would be the most profitable to start with?thank you!\nnormal,dropped and broke display screen on the cement. spent 2 days looking for solutions to transfer the data as i did not have some photos and videos get backed up. tried many alternatives with fail until i found your video. this happened last thursday and just ordered the usb c hub adapter today saturday. should be here tuesday so feeling hopeful this will be the key to the solution i have been looking for. many many thanks for creating this video and i am sure it is indeed loads of help to folks like me. again thank you.\nquestion,wow! i'm really impressed that you were able to generate a summary from a 117-page pdf. i've been hoping to use chatgpt to read long reports like this. can you tell me how you did it? i don't know anything about coding but i was wondering if you could develop this summary function into a standalone software?\nquestion,on different topic do you know of good resources and examples to apply sequence prediction maybe using directed graphs like product recommendation / next event prediction?\nquestion,did you find the answer to why the train dataset is smaller than the test? i've encountered the same problem with every graph dataset i've used. although one thing i did notice is that the validation accuracy did not increase when i used the larger one as train in any of the graphs and in a couple of cases it even decreased.\n","output_type":"stream"}]}]}